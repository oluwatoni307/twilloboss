<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Voice Assistant Test</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        padding: 20px;
      }
      label {
        display: block;
        margin-top: 10px;
      }
      button {
        margin-top: 20px;
        padding: 10px 20px;
        font-size: 16px;
      }
      audio {
        display: block;
        margin-top: 20px;
      }
    </style>
  </head>
  <body>
    <h1>Test Real-Time Voice Assistant</h1>

    <label>
      Language:
      <input type="text" id="language" value="English" />
    </label>

    <label>
      Accent:
      <input type="text" id="accent" value="British" />
    </label>

    <label>
      User Prompt:
      <input
        type="text"
        id="userPrompt"
        value="Tell me a fun fact about space"
      />
    </label>

    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <span id="status">Status: Idle</span>

    <audio id="assistantAudio" controls autoplay></audio>

    <script>
      let ms = null;
      let pc = null;

      async function startAssistant(Language, Accent, UserPrompt) {
        document.getElementById("stopBtn").disabled = false;
        document.getElementById("startBtn").disabled = true;

        try {
          let prompt = `
    You are an elite real‑time conversational voice assistant, designed for clarity and expressiveness.
    • Language: Speak flawlessly in ${Language}, with native‑level fluency.
    • Accent: Embrace the full character of a ${Accent} accent—honoring its unique phonetics, rhythm, and intonation.
    • Instruction: Listen fully, then engage in a natural, conversational style as you follow the user’s request: ${UserPrompt}.
    `;

          const tokenResponse = await fetch(
            "https://twilloboss.onrender.com/session",
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ prompt }),
            }
          );

          if (!tokenResponse.ok)
            throw new Error("Failed to retrieve ephemeral key");

          const EPHEMERAL_KEY = await tokenResponse.json();
          pc = new RTCPeerConnection();

          const audioEl = document.getElementById("assistantAudio");

          pc.ontrack = (e) => {
            console.log("Received audio track");
            audioEl.srcObject = e.streams[0];
          };

          ms = await navigator.mediaDevices.getUserMedia({ audio: true });
          pc.addTrack(ms.getTracks()[0]);

          const dc = pc.createDataChannel("oai-events");
          dc.addEventListener("message", (e) => {
            console.log("Received event:", e.data);
          });

          const offer = await pc.createOffer();
          await pc.setLocalDescription(offer);

          const sdpResponse = await fetch(
            "https://api.openai.com/v1/realtime",
            {
              method: "POST",
              body: offer.sdp,
              headers: {
                Authorization: `Bearer ${EPHEMERAL_KEY}`,
                "Content-Type": "application/sdp",
              },
            }
          );

          if (!sdpResponse.ok)
            throw new Error("Failed to establish session with OpenAI");

          const answer = {
            type: "answer",
            sdp: await sdpResponse.text(),
          };

          await pc.setRemoteDescription(answer);
          console.log("Session established!");

          dc.addEventListener("open", () => {
            console.log("Data channel is open — sending greeting...");
            dc.send(
              JSON.stringify({
                type: "response.create",
                response: {
                  instructions:
                    "Say: Hello, this is Brandy. How can I help you today?",
                },
              })
            );
          });

          window.addEventListener("beforeunload", () => {
            ms.getTracks().forEach((track) => track.stop());
            pc.close();
          });
        } catch (error) {
          console.error("Error:", error);
          alert("Error: " + error.message);
        }
      }

      function stopAssistant() {
        if (ms) {
          ms.getTracks().forEach((track) => track.stop());
          ms = null;
        }
        if (pc) {
          pc.close();
          pc = null;
        }
        document.getElementById("status").innerText = "Status: Stopped";
        document.getElementById("stopBtn").disabled = true;
        document.getElementById("startBtn").disabled = false;
      }

      document.getElementById("stopBtn").addEventListener("click", () => {
        stopAssistant();
      });

      window.addEventListener("beforeunload", () => {
        stopAssistant();
      });

      document
        .getElementById("startBtn")
        .addEventListener("click", async () => {
          const language = document.getElementById("language").value;
          const accent = document.getElementById("accent").value;
          const userPrompt = document.getElementById("userPrompt").value;

          await startAssistant(language, accent, userPrompt);
        });
    </script>
  </body>
</html>
